# MLOps Pipeline â€“ Complete Machine Learning Deployment Solution

A comprehensive MLOps pipeline for deploying machine learning models with production-ready features including automated training, API deployment, monitoring, and CI/CD.

## ğŸš€ Features

- **Automated Model Training**: Support for multiple algorithms (Logistic Regression, Random Forest)
- **RESTful API**: FastAPI-based API with comprehensive documentation
- **Data Management**: Robust data loading, preprocessing, and validation
- **Model Monitoring**: Performance tracking and health checks
- **Configuration Management**: Environment-based configuration
- **Docker Support**: Multi-stage builds for development and production
- **CI/CD Pipeline**: GitHub Actions workflow with testing and deployment
- **Comprehensive Testing**: Unit tests, integration tests, and model validation
- **Logging & Monitoring**: Detailed logging and system metrics

## ğŸ“‹ Requirements

- Python 3.9+
- Docker (optional)
- Git

## ğŸ› ï¸ Installation

### Local Development

1. **Clone the repository**
   ```bash
   git clone https://github.com/FayssalSabri/mlops-pipeline.git
   cd mlops-pipeline
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Train a model**
   ```bash
   python src/train.py --model logistic
   ```

5. **Start the API**
   ```bash
   uvicorn src.api:app --reload
   ```

### Docker Deployment

1. **Build and run with Docker Compose**
   ```bash
   # Production
   docker-compose up --build

   # Development
   docker-compose --profile dev up --build
   ```

2. **Or build manually**
   ```bash
   # Build production image
   docker build --target production -t mlops-pipeline .

   # Run container
   docker run -p 8000:8000 mlops-pipeline
   ```

## ğŸ“– Usage

### API Endpoints

Once the API is running, you can access:

- **API Documentation**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health
- **Model Info**: http://localhost:8000/model/info

### Making Predictions

**Single Prediction**
```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "feature1": 45.5,
       "feature2": 28.3,
       "feature3": 22.1
     }'
```

**Batch Predictions**
```bash
curl -X POST "http://localhost:8000/predict/batch" \
     -H "Content-Type: application/json" \
     -d '{
       "data": [
         {"feature1": 45.5, "feature2": 28.3, "feature3": 22.1},
         {"feature1": 30.2, "feature2": 35.1, "feature3": 18.9}
       ]
     }'
```

### Training Models

**Basic Training**
```bash
python src/train.py
```

**Advanced Training**
```bash
# Train Random Forest model
python src/train.py --model random_forest --test-size 0.3

# Train with custom data
python src/train.py --data data/my_dataset.csv --model logistic
```

## âš™ï¸ Configuration

The application can be configured using environment variables or a configuration file:

### Environment Variables

```bash
# Application settings
export APP_DEBUG=false
export APP_PORT=8000

# Model settings
export MODEL_TYPE=logistic
export MODEL_PATH=models/model.pkl

# Data settings
export DATA_TEST_SIZE=0.2
export DATA_RANDOM_STATE=42

# Logging
export LOG_LEVEL=INFO
```

### Configuration File

Create a `config.json` file:

```json
{
  "app": {
    "debug": false,
    "port": 8000
  },
  "model": {
    "type": "logistic",
    "path": "models/model.pkl"
  },
  "data": {
    "test_size": 0.2,
    "random_state": 42
  }
}
```

## ğŸ§ª Testing

Run the test suite:

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test file
pytest tests/test_api.py -v
```

## ğŸ“Š Monitoring

The application includes comprehensive monitoring:

- **Performance Metrics**: CPU, memory, disk usage
- **Model Metrics**: Prediction accuracy, processing time
- **Health Checks**: System and model health status
- **Logging**: Structured logging with different levels

Access monitoring data:
- Logs: `logs/` directory
- Health status: `GET /health`
- Model metrics: `GET /model/metrics`

## ğŸš€ CI/CD Pipeline

The project includes a GitHub Actions workflow that:

1. **Tests**: Runs unit tests across Python versions
2. **Linting**: Code quality checks with flake8, black, isort
3. **Security**: Security scanning with Bandit and Safety
4. **Build**: Creates Docker images
5. **Deploy**: Deploys to production (configurable)

## ğŸ“ Project Structure

```
mlops-pipeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api.py              # FastAPI application
â”‚   â”œâ”€â”€ train.py            # Model training script
â”‚   â”œâ”€â”€ predict.py          # Prediction utilities
â”‚   â”œâ”€â”€ data_loader.py      # Data management
â”‚   â”œâ”€â”€ config.py           # Configuration management
â”‚   â””â”€â”€ monitoring.py       # Monitoring and logging
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api.py         # API tests
â”‚   â”œâ”€â”€ test_data_loader.py # Data loader tests
â”‚   â””â”€â”€ test_config.py      # Configuration tests
â”œâ”€â”€ models/                 # Trained models
â”œâ”€â”€ logs/                   # Application logs
â”œâ”€â”€ data/                   # Data files
â”œâ”€â”€ .github/workflows/      # CI/CD workflows
â”œâ”€â”€ Dockerfile              # Multi-stage Docker build
â”œâ”€â”€ docker-compose.yml      # Docker Compose configuration
â””â”€â”€ requirements.txt        # Python dependencies
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

If you encounter any issues or have questions:

1. Check the [Issues](https://github.com/<your-username>/mlops-pipeline/issues) page
2. Create a new issue with detailed information
3. Contact the maintainers

## ğŸ”„ Changelog

### v1.0.0
- Initial release
- FastAPI-based REST API
- Model training and prediction
- Docker support
- CI/CD pipeline
- Comprehensive testing
- Monitoring and logging